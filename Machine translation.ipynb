{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "\n",
    "### Changes\n",
    "- Used LSTM instead of GRU; adam instead of SGD\n",
    "- Not used dropout, just for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from random import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import io\n",
    "import unicodedata\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.core.debugger import Tracer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk import word_tokenize\n",
    "\n",
    "softmax = nn.Softmax()\n",
    "use_cuda = use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "('fra', 4489)\n",
      "('eng', 2925)\n",
      "[u'je suis sur que tu vas reussir .', u'i m sure that you ll succeed .']\n"
     ]
    }
   ],
   "source": [
    "# Data acuitition\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = io.open('data_att/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))\n",
    "\n",
    "\n",
    "# Get cuda variables\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "def compute_bleu(reference_sentence, predicted_sentence):\n",
    "    \"\"\"\n",
    "    Given a reference sentence, and a predicted sentence, compute the BLEU similary between them.\n",
    "    \"\"\"\n",
    "    reference_tokenized = word_tokenize(reference_sentence.lower())\n",
    "    predicted_tokenized = word_tokenize(predicted_sentence.lower())\n",
    "    return sentence_bleu([reference_tokenized], predicted_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # use some trainable embedding (size hidden_size) instead of one-hot\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1,1,self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return(result.cuda(), result.cuda())\n",
    "        else:\n",
    "            return (result,result)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size): # input size is same as hidden_size\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1,1,self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return (result.cuda(), result.cuda())\n",
    "        else:\n",
    "            return result, result\n",
    "        \n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, max_length):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        # input size = hidden size assumed\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.max_length = max_length\n",
    "        # dropout not used for now\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size *2 , self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        # ignored dropout\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward():    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_var, target_var, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # no of words in input and target\n",
    "    input_length = input_var.size()[0]\n",
    "    target_length = target_var.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    for ei in range(input_length):\n",
    "        enc_output, encoder_hidden = encoder(input_var[ei],encoder_hidden)\n",
    "        encoder_outputs[ei] = enc_output[0][0]\n",
    "\n",
    "    decoder_input =  Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    loss = 0\n",
    "    output_sentence = []\n",
    "    for di in range(target_length):\n",
    "        target_variable = target_var[di]\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = softmax(decoder_output[0][0]).data.topk(1)\n",
    "        ni = topi[0]\n",
    "        predicted_word = output_lang.index2word[ni]\n",
    "        output_sentence.append(predicted_word)\n",
    "\n",
    "        if random.random() < teacher_forcing_ratio:\n",
    "            decoder_input = target_var[di]\n",
    "        else:\n",
    "            decoder_input = Variable(torch.LongTensor([ni]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        loss+=criterion(decoder_output[0], target_variable)\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    return (loss.data[0]/target_length, output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder  = Decoder(hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Mean - 0.801884174347 | Value - 0.801884174347\n",
      "i m .\n",
      "i m . EOS\n",
      "\n",
      "20 Mean - 1.32915485019 | Value - 1.09625177383\n",
      "i m calm .\n",
      "i m . . EOS\n",
      "\n",
      "40 Mean - 1.21077225034 | Value - 1.3781244278\n",
      "i m safe .\n",
      "i m fat . EOS\n",
      "\n",
      "60 Mean - 1.41043026799 | Value - 2.12527751923\n",
      "he s rich .\n",
      "he m . . EOS\n",
      "\n",
      "80 Mean - 1.47973383523 | Value - 2.29331073761\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 1.26990938187 | Value - 1.26990938187\n",
      "i m .\n",
      "i m lazy EOS\n",
      "\n",
      "20 Mean - 1.03202776001 | Value - 0.79400844574\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.913121565377 | Value - 0.922255420685\n",
      "i m safe .\n",
      "i m lazy . EOS\n",
      "\n",
      "60 Mean - 0.957338267988 | Value - 0.948811721802\n",
      "he s rich .\n",
      "he s wet . EOS\n",
      "\n",
      "80 Mean - 1.06532614476 | Value - 1.54863367081\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 1.10468626022 | Value - 1.10468626022\n",
      "i m .\n",
      "i m lazy EOS\n",
      "\n",
      "20 Mean - 0.965221554892 | Value - 0.813848876953\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.880181848712 | Value - 0.95529384613\n",
      "i m safe .\n",
      "i m lazy . EOS\n",
      "\n",
      "60 Mean - 0.87746598004 | Value - 0.636675930023\n",
      "he s rich .\n",
      "he s wet . EOS\n",
      "\n",
      "80 Mean - 0.997517905019 | Value - 1.02779493332\n",
      "i m armed .\n",
      "i am sure . EOS\n",
      "\n",
      "0 Mean - 0.925477981567 | Value - 0.925477981567\n",
      "i m .\n",
      "i m lazy EOS\n",
      "\n",
      "20 Mean - 0.937308554422 | Value - 0.805695533752\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.855189200145 | Value - 0.930425834656\n",
      "i m safe .\n",
      "i m lazy . EOS\n",
      "\n",
      "60 Mean - 0.849557384376 | Value - 0.60656337738\n",
      "he s rich .\n",
      "he s lazy . EOS\n",
      "\n",
      "80 Mean - 0.947330609663 | Value - 1.22290630341\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 2.74299192429 | Value - 2.74299192429\n",
      "i m .\n",
      "i m lazy .\n",
      "\n",
      "20 Mean - 0.958407856169 | Value - 0.798061800003\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.858667627195 | Value - 0.942280197144\n",
      "i m safe .\n",
      "i m lazy . EOS\n",
      "\n",
      "60 Mean - 0.843653222121 | Value - 0.604118490219\n",
      "he s rich .\n",
      "he s lazy . EOS\n",
      "\n",
      "80 Mean - 0.949413160826 | Value - 1.21422195435\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 0.816337585449 | Value - 0.816337585449\n",
      "i m .\n",
      "i m cold EOS\n",
      "\n",
      "20 Mean - 0.876966685341 | Value - 0.829678630829\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.825390864582 | Value - 0.941796398163\n",
      "i m safe .\n",
      "i m lazy . EOS\n",
      "\n",
      "60 Mean - 0.816334079263 | Value - 0.541159629822\n",
      "he s rich .\n",
      "he s a . EOS\n",
      "\n",
      "80 Mean - 0.911737263448 | Value - 1.17681398392\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 0.816222786903 | Value - 0.816222786903\n",
      "i m .\n",
      "i m . EOS\n",
      "\n",
      "20 Mean - 0.861182095891 | Value - 0.7943171978\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.78881172029 | Value - 0.947832012177\n",
      "i m safe .\n",
      "i m fine . EOS\n",
      "\n",
      "60 Mean - 0.760752544377 | Value - 0.48715596199\n",
      "he s rich .\n",
      "he s good . EOS\n",
      "\n",
      "80 Mean - 0.87064368509 | Value - 0.806575679779\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 0.744307935238 | Value - 0.744307935238\n",
      "i m .\n",
      "i m . EOS\n",
      "\n",
      "20 Mean - 0.822312397616 | Value - 0.810931587219\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.787107900585 | Value - 0.932120418549\n",
      "i m safe .\n",
      "i m fine . EOS\n",
      "\n",
      "60 Mean - 0.759077439608 | Value - 0.47207493782\n",
      "he s rich .\n",
      "he s good . EOS\n",
      "\n",
      "80 Mean - 0.846042190216 | Value - 0.764357471466\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 0.74144333601 | Value - 0.74144333601\n",
      "i m .\n",
      "i m cold EOS\n",
      "\n",
      "20 Mean - 0.858984419845 | Value - 0.784926700592\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.775612055092 | Value - 0.907576179504\n",
      "i m safe .\n",
      "i m lazy . EOS\n",
      "\n",
      "60 Mean - 0.748254803295 | Value - 0.453311061859\n",
      "he s rich .\n",
      "he s rich . EOS\n",
      "\n",
      "80 Mean - 0.833421494392 | Value - 1.34639635086\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n",
      "0 Mean - 0.755059361458 | Value - 0.755059361458\n",
      "i m .\n",
      "i m cold EOS\n",
      "\n",
      "20 Mean - 0.870309864907 | Value - 0.75005812645\n",
      "i m calm .\n",
      "i m lazy . EOS\n",
      "\n",
      "40 Mean - 0.778861424981 | Value - 0.832800388336\n",
      "i m safe .\n",
      "i m lazy . EOS\n",
      "\n",
      "60 Mean - 0.721134432548 | Value - 0.35518848896\n",
      "he s rich .\n",
      "he s rich . EOS\n",
      "\n",
      "80 Mean - 0.790142457279 | Value - 0.712966966629\n",
      "i m armed .\n",
      "i am lazy . EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define encoder\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "hidden_size = 256\n",
    "teacher_forcing_ratio = 0.5\n",
    "print_every = 20\n",
    "input_size = input_lang.n_words # since one hot encoding is used\n",
    "output_size = output_lang.n_words\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# there is no SOS in sentences\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for pi in range(len(pairs[0:100])):\n",
    "        sentence_pair = pairs[pi]\n",
    "        train_pair = variablesFromPair(sentence_pair)\n",
    "        input_var = train_pair[0]\n",
    "        target_var = train_pair[1]\n",
    "        loss, predicted_sentence = train(input_var, target_var, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        losses.append(loss)\n",
    "\n",
    "        if pi%print_every==0:\n",
    "            print(str(pi) + \" Mean - \" + str(np.mean(losses)) + ' | Value - ' + str(losses[-1]))\n",
    "            print (sentence_pair[1])\n",
    "            print (' '.join(predicted_sentence))\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> i am lazy . EOS\n",
      "<SOS> i m lazy . EOS\n",
      "0.604275079471\n",
      "\n",
      "\n",
      "<SOS> i m early . EOS\n",
      "<SOS> i m lazy . EOS\n",
      "0.795270728767\n",
      "\n",
      "\n",
      "<SOS> i m ready ! EOS\n",
      "<SOS> i m lazy . EOS\n",
      "0.622332977288\n",
      "\n",
      "\n",
      "<SOS> i m finicky . EOS\n",
      "<SOS> i m lazy . EOS\n",
      "0.795270728767\n",
      "\n",
      "\n",
      "<SOS> you re free . EOS\n",
      "<SOS> i m lazy . EOS\n",
      "0.56234132519\n",
      "\n",
      "\n",
      "<SOS> you re good . EOS\n",
      "<SOS> i m sure . EOS\n",
      "0.56234132519\n",
      "\n",
      "\n",
      "<SOS> he is a poet . EOS\n",
      "<SOS> he s rich . EOS\n",
      "0.509523147161\n",
      "\n",
      "\n",
      "<SOS> i m outraged . EOS\n",
      "<SOS> i m fussy . EOS\n",
      "0.795270728767\n",
      "\n",
      "\n",
      "<SOS> we re pooped . EOS\n",
      "<SOS> i m sure . EOS\n",
      "0.56234132519\n",
      "\n",
      "\n",
      "<SOS> he s a senior . EOS\n",
      "<SOS> i m sure . EOS\n",
      "0.46040613666\n",
      "\n",
      "\n",
      "Mean - 0.674515222885\n"
     ]
    }
   ],
   "source": [
    "def seq2seq_inference(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_var = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_var.size()[0]\n",
    "    en_hidden_var = encoder.initHidden()\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    for ei in range(input_length):\n",
    "        enc_output, encoder_hidden = encoder(input_var[ei],encoder_hidden)\n",
    "        encoder_outputs[ei] = enc_output[0][0]\n",
    "\n",
    "    decoder_input =  Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    decoder_hidden = encoder_hidden\n",
    "    output_sentence = []\n",
    "\n",
    "    ni=-1\n",
    "    while ni != EOS_token:\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = softmax(decoder_output[0][0]).data.topk(1)\n",
    "        ni = topi[0]\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        predicted_word = output_lang.index2word[ni]\n",
    "        output_sentence.append(predicted_word)\n",
    "        \n",
    "    return output_sentence\n",
    "\n",
    "all_bleu = []\n",
    "for sentence_pair in pairs[0:1000]:\n",
    "    input_sentence = sentence_pair[0]\n",
    "    output_sentence = seq2seq_inference(encoder, decoder, input_sentence)\n",
    "    orig_sentence = sentence_pair[1] + ' EOS'\n",
    "    out_sentence = ' '.join(output_sentence)\n",
    "    bleu_score = compute_bleu(orig_sentence, out_sentence)\n",
    "    all_bleu.append(bleu_score)\n",
    "    orig_sentence = '<SOS> ' +  orig_sentence\n",
    "    out_sentence = '<SOS> ' +  out_sentence    \n",
    "    \n",
    "    if random.random() <0.01:\n",
    "        print(orig_sentence)\n",
    "        print(out_sentence)\n",
    "        print(bleu_score)\n",
    "        print('\\n')\n",
    "    \n",
    "print('Mean - ' + str(np.mean(all_bleu)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
